# AnySplat ä¸­ Voxelized 3D Gaussians ç”Ÿæˆæµç¨‹ä»£ç æ ‡æ³¨

æœ¬æ–‡æ¡£è¯¦ç»†æ ‡æ³¨äº† AnySplat ä¸­ä»è¾“å…¥å›¾åƒç”Ÿæˆ Voxelized 3D Gaussians çš„å®Œæ•´æµç¨‹å’Œå¯¹åº”ä»£ç ä½ç½®ã€‚

---

## ğŸ“ ä¸»è¦æµç¨‹æ¦‚è§ˆ

```
è¾“å…¥å›¾åƒ (image)
    â†“
æ­¥éª¤1: VGGT Encoder ç‰¹å¾æå– (Line 525-529)
    â†“
æ­¥éª¤2: é¢„æµ‹ç›¸æœºå§¿æ€å’Œæ·±åº¦å›¾ (Line 532-552)
    â†“
æ­¥éª¤3: æ·±åº¦å›¾åæŠ•å½±åˆ°3Dç‚¹äº‘ (Line 550-552)
    â†“
æ­¥éª¤4: Gaussianå‚æ•°é¢„æµ‹å¤´ (Line 564-571)
    â†“
æ­¥éª¤5: ã€æ ¸å¿ƒã€‘ä½“ç´ åŒ–ä¸ç‰¹å¾èåˆ (Line 582-597)
    â†“
æ­¥éª¤6: Opacityå’Œå¯†åº¦æå– (Line 608-621)
    â†“
æ­¥éª¤7: Gaussian Adapterè½¬æ¢ (Line 653-658)
    â†“
è¾“å‡º: Gaussianså¯¹è±¡ (åŒ…å«means, covariances, harmonics, opacitiesç­‰)
```

---

## ğŸ” è¯¦ç»†ä»£ç ä½ç½®æ ‡æ³¨

### **æ–‡ä»¶**: `src/model/encoder/anysplat.py`

---

### **æ­¥éª¤1: VGGT Encoder ç‰¹å¾èšåˆ**
**ä½ç½®**: `EncoderAnySplat.forward()` - Line 525-529

```python
# ä½ç½®: Line 525-529
with torch.amp.autocast("cuda", enabled=True, dtype=torch.bfloat16):
    aggregated_tokens_list, patch_start_idx = self.aggregator(
        image.to(torch.bfloat16),
        intermediate_layer_idx=self.cfg.intermediate_layer_idx,
    )
```
**ä½œç”¨**: ä½¿ç”¨VGGTèšåˆå™¨å¯¹å¤šè§†è§’å›¾åƒè¿›è¡Œç‰¹å¾æå–ï¼Œç”Ÿæˆèšåˆçš„tokenåˆ—è¡¨ã€‚

---

### **æ­¥éª¤2: é¢„æµ‹ç›¸æœºå§¿æ€å’Œæ·±åº¦/ç‚¹äº‘**
**ä½ç½®**: `EncoderAnySplat.forward()` - Line 531-552

```python
# ä½ç½®: Line 532-536
pred_pose_enc_list = self.camera_head(aggregated_tokens_list)
last_pred_pose_enc = pred_pose_enc_list[-1]
extrinsic, intrinsic = pose_encoding_to_extri_intri(
    last_pred_pose_enc, image.shape[-2:]
)

# ä½ç½®: Line 538-552
if self.cfg.pred_head_type == "point":
    pts_all, pts_conf = self.point_head(
        aggregated_tokens_list,
        images=image,
        patch_start_idx=patch_start_idx,
    )
elif self.cfg.pred_head_type == "depth":
    depth_map, depth_conf = self.depth_head(
        aggregated_tokens_list,
        images=image,
        patch_start_idx=patch_start_idx,
    )
    pts_all = batchify_unproject_depth_map_to_point_map(
        depth_map, extrinsic, intrinsic
    )
```
**ä½œç”¨**: 
- é¢„æµ‹ç›¸æœºå¤–å‚(extrinsic)å’Œå†…å‚(intrinsic)
- é¢„æµ‹æ·±åº¦å›¾æˆ–ç›´æ¥é¢„æµ‹3Dç‚¹äº‘
- å°†æ·±åº¦å›¾åæŠ•å½±åˆ°3Dç©ºé—´å¾—åˆ° `pts_all` (å½¢çŠ¶: `[B, V, H, W, 3]`)

---

### **æ­¥éª¤3: Gaussianå‚æ•°é¢„æµ‹å¤´**
**ä½ç½®**: `EncoderAnySplat.forward()` - Line 564-571

```python
# ä½ç½®: Line 564-571
out = self.gaussian_param_head(
    aggregated_tokens_list,
    pts_all.flatten(0, 1).permute(0, 3, 1, 2),
    image,
    patch_start_idx=patch_start_idx,
    image_size=(h, w),
)
```
**ä½œç”¨**: 
- è¾“å…¥: èšåˆç‰¹å¾tokens + 3Dç‚¹äº‘ + åŸå§‹å›¾åƒ
- è¾“å‡º: `out` åŒ…å«æ¯ä¸ªåƒç´ çš„Gaussianå‚æ•°
  - `out[:, :, :self.raw_gs_dim]` = `anchor_feats` (åŒ…å«opacity + scales + rotations + SHç³»æ•°)
  - `out[:, :, self.raw_gs_dim]` = `conf` (ç½®ä¿¡åº¦)

---

### **æ­¥éª¤4: ã€æ ¸å¿ƒã€‘ä½“ç´ åŒ–ä¸ç‰¹å¾èåˆ**
**ä½ç½®**: `EncoderAnySplat.forward()` - Line 579-597

```python
# ä½ç½®: Line 579
anchor_feats, conf = out[:, :, : self.raw_gs_dim], out[:, :, self.raw_gs_dim]

# ä½ç½®: Line 581-597
neural_feats_list, neural_pts_list = [], []
if self.cfg.voxelize:  # å¦‚æœå¯ç”¨ä½“ç´ åŒ–
    for b_i in range(b):
        # ã€å…³é”®ã€‘è°ƒç”¨ä½“ç´ åŒ–èåˆå‡½æ•°
        neural_pts, neural_feats = self.voxelizaton_with_fusion(
            anchor_feats[b_i],
            pts_all[b_i].permute(0, 3, 1, 2).contiguous(),
            self.voxel_size,
            conf=conf[b_i],
        )
        neural_feats_list.append(neural_feats)
        neural_pts_list.append(neural_pts)
else:  # ä¸ä½¿ç”¨ä½“ç´ åŒ–ï¼Œç›´æ¥æŒ‰ç½®ä¿¡åº¦maskç­›é€‰
    for b_i in range(b):
        neural_feats_list.append(
            anchor_feats[b_i].permute(0, 2, 3, 1)[conf_valid_mask[b_i]]
        )
        neural_pts_list.append(pts_all[b_i][conf_valid_mask[b_i]])
```
**ä½œç”¨**: 
- **å¦‚æœ `voxelize=True`**: è°ƒç”¨ `voxelizaton_with_fusion()` å°†åƒç´ çº§Gaussiansåˆå¹¶åˆ°ä½“ç´ ä¸­
- **å¦‚æœ `voxelize=False`**: ç›´æ¥æŒ‰ç½®ä¿¡åº¦maskç­›é€‰åƒç´ çº§Gaussians

---

### **æ­¥éª¤5: ã€æ ¸å¿ƒç®—æ³•ã€‘ä½“ç´ åŒ–èåˆå‡½æ•°è¯¦è§£**
**ä½ç½®**: `EncoderAnySplat.voxelizaton_with_fusion()` - Line 409-446

```python
# ä½ç½®: Line 409-446
def voxelizaton_with_fusion(self, img_feat, pts3d, voxel_size, conf=None):
    """
    è¾“å…¥:
        img_feat: [B*V, C, H, W] - å›¾åƒç‰¹å¾
        pts3d: [B*V, 3, H, W] - 3Dç‚¹åæ ‡
        voxel_size: ä½“ç´ å¤§å°
        conf: [B*V, H, W] - ç½®ä¿¡åº¦
    è¾“å‡º:
        voxel_pts: [num_unique_voxels, 3] - ä½“ç´ ä¸­å¿ƒåæ ‡
        voxel_feats: [num_unique_voxels, feat_dim] - èåˆåçš„ç‰¹å¾
    """
    V, C, H, W = img_feat.shape
    pts3d_flatten = pts3d.permute(0, 2, 3, 1).flatten(0, 2)  # [B*V*N, 3]
    
    # ã€æ­¥éª¤5.1ã€‘è®¡ç®—ä½“ç´ ç´¢å¼• (Line 415)
    voxel_indices = (pts3d_flatten / voxel_size).round().int()  # [B*V*N, 3]
    
    # ã€æ­¥éª¤5.2ã€‘æ‰¾åˆ°å”¯ä¸€ä½“ç´  (Line 416-418)
    unique_voxels, inverse_indices, counts = torch.unique(
        voxel_indices, dim=0, return_inverse=True, return_counts=True
    )
    
    # ã€æ­¥éª¤5.3ã€‘å±•å¹³ç½®ä¿¡åº¦å’Œç‰¹å¾ (Line 421-422)
    conf_flat = conf.flatten()  # [B*V*N]
    anchor_feats_flat = img_feat.permute(0, 2, 3, 1).flatten(0, 2)  # [B*V*N, feat_dim]
    
    # ã€æ­¥éª¤5.4ã€‘åŸºäºç½®ä¿¡åº¦çš„SoftmaxåŠ æƒèåˆ (Line 425-432)
    conf_voxel_max, _ = scatter_max(conf_flat, inverse_indices, dim=0)
    conf_exp = torch.exp(conf_flat - conf_voxel_max[inverse_indices])
    voxel_weights = scatter_add(conf_exp, inverse_indices, dim=0)
    weights = (conf_exp / (voxel_weights[inverse_indices] + 1e-6)).unsqueeze(-1)
    
    # ã€æ­¥éª¤5.5ã€‘åŠ æƒå¹³å‡ä½ç½®å’Œç‰¹å¾ (Line 434-436)
    weighted_pts = pts3d_flatten * weights
    weighted_feats = anchor_feats_flat.squeeze(1) * weights
    
    # ã€æ­¥éª¤5.6ã€‘æŒ‰ä½“ç´ èšåˆ (Line 438-444)
    voxel_pts = scatter_add(weighted_pts, inverse_indices, dim=0)  # [num_unique_voxels, 3]
    voxel_feats = scatter_add(weighted_feats, inverse_indices, dim=0)  # [num_unique_voxels, feat_dim]
    
    return voxel_pts, voxel_feats
```
**ç®—æ³•è¯´æ˜**:
1. **ä½“ç´ ç´¢å¼•è®¡ç®—**: å°†3Dç‚¹åæ ‡é™¤ä»¥ä½“ç´ å¤§å°å¹¶å–æ•´ï¼Œå¾—åˆ°æ¯ä¸ªç‚¹æ‰€å±çš„ä½“ç´ ç´¢å¼•
2. **å”¯ä¸€ä½“ç´ æå–**: ä½¿ç”¨ `torch.unique` æ‰¾å‡ºæ‰€æœ‰å”¯ä¸€çš„ä½“ç´ 
3. **ç½®ä¿¡åº¦åŠ æƒ**: ä½¿ç”¨ç½®ä¿¡åº¦çš„softmaxä½œä¸ºæƒé‡ï¼Œå¯¹è½åœ¨åŒä¸€ä½“ç´ ä¸­çš„å¤šä¸ªåƒç´ ç‚¹è¿›è¡ŒåŠ æƒèåˆ
4. **ä½ç½®å’Œç‰¹å¾èšåˆ**: ä½¿ç”¨ `scatter_add` å°†åŠ æƒåçš„ä½ç½®å’Œç‰¹å¾èšåˆåˆ°å¯¹åº”ä½“ç´ 

**å…³é”®ç‰¹ç‚¹**:
- å‡å°‘Gaussianæ•°é‡ï¼šä»åƒç´ çº§ (HÃ—WÃ—V) å‡å°‘åˆ°ä½“ç´ çº§ (num_unique_voxels)
- ä¿æŒç‰¹å¾è´¨é‡ï¼šé€šè¿‡ç½®ä¿¡åº¦åŠ æƒèåˆï¼Œä¿ç•™é«˜è´¨é‡ç‰¹å¾ä¿¡æ¯
- ç©ºé—´ä¸€è‡´æ€§ï¼šåŒä¸€ä½“ç´ å†…çš„å¤šä¸ªè§‚æµ‹è¢«èåˆï¼Œæé«˜ç©ºé—´ä¸€è‡´æ€§

---

### **æ­¥éª¤6: Paddingå’Œç»´åº¦ç»Ÿä¸€**
**ä½ç½®**: `EncoderAnySplat.forward()` - Line 599-606

```python
# ä½ç½®: Line 599-606
max_voxels = max(f.shape[0] for f in neural_feats_list)
neural_feats = self.pad_tensor_list(
    neural_feats_list, (max_voxels,), value=-1e10
)
neural_pts = self.pad_tensor_list(
    neural_pts_list, (max_voxels,), -1e4
)  # -1e4 == invalid voxel marker
```
**ä½œç”¨**: å°†ä¸åŒbatchçš„ä½“ç´ æ•°é‡padåˆ°ç›¸åŒé•¿åº¦ï¼Œä¾¿äºbatchå¤„ç†ã€‚

---

### **æ­¥éª¤7: Opacityå’Œæ·±åº¦æå–**
**ä½ç½®**: `EncoderAnySplat.forward()` - Line 608-621

```python
# ä½ç½®: Line 608-609
depths = neural_pts[..., -1].unsqueeze(-1)  # ä»3Dç‚¹ä¸­æå–æ·±åº¦
densities = neural_feats[..., 0].sigmoid()   # ç¬¬ä¸€ä¸ªç‰¹å¾ç»´åº¦æ˜¯density

# ä½ç½®: Line 614
opacity = self.map_pdf_to_opacity(densities, global_step).squeeze(-1)

# ä½ç½®: Line 615-621 (å¯é€‰ï¼Œå¦‚æœå¯ç”¨opacity_conf)
if self.cfg.opacity_conf:
    shift = torch.quantile(depth_conf, self.cfg.conf_threshold)
    opacity = opacity * torch.sigmoid(depth_conf - shift)[
        conf_valid_mask
    ].unsqueeze(0)
```
**ä½œç”¨**: 
- ä»ä½“ç´ åŒ–åçš„ç‰¹å¾ä¸­æå–æ·±åº¦å’Œå¯†åº¦
- ä½¿ç”¨ `map_pdf_to_opacity()` å°†å¯†åº¦è½¬æ¢ä¸ºopacity
- å¯é€‰ï¼šä½¿ç”¨ç½®ä¿¡åº¦è¿›ä¸€æ­¥è°ƒæ•´opacity

---

### **æ­¥éª¤8: Gaussianå‰ªæ (å¯é€‰)**
**ä½ç½®**: `EncoderAnySplat.forward()` - Line 626-651

```python
# ä½ç½®: Line 626-651
if gs_prune and b == 1:
    opacity_threshold = self.cfg.opacity_threshold
    gaussian_usage = opacity > opacity_threshold  # (B, N)
    
    # å¦‚æœä¿ç•™æ¯”ä¾‹è¶…è¿‡é˜ˆå€¼ï¼ŒæŒ‰opacityæ’åºä¿ç•™å‰Nä¸ª
    if (gaussian_usage.sum() / gaussian_usage.numel()) > self.cfg.gs_keep_ratio:
        num_keep = int(gaussian_usage.shape[1] * self.cfg.gs_keep_ratio)
        idx_sort = opacity.argsort(dim=1, descending=True)
        keep_idx = idx_sort[:, :num_keep]
        gaussian_usage = torch.zeros_like(gaussian_usage, dtype=torch.bool)
        gaussian_usage.scatter_(1, keep_idx, True)
    
    # æ ¹æ®usage maskç­›é€‰Gaussians
    neural_pts = neural_pts[gaussian_usage].view(b, -1, 3).contiguous()
    depths = depths[gaussian_usage].view(b, -1, 1).contiguous()
    neural_feats = neural_feats[gaussian_usage].view(b, -1, self.raw_gs_dim).contiguous()
    opacity = opacity[gaussian_usage].view(b, -1).contiguous()
```
**ä½œç”¨**: æ ¹æ®opacityé˜ˆå€¼æˆ–ä¿ç•™æ¯”ä¾‹ï¼Œå‰ªææ‰ä½è´¨é‡çš„Gaussiansã€‚

---

### **æ­¥éª¤9: ã€æœ€ç»ˆã€‘è½¬æ¢ä¸ºGaussianså¯¹è±¡**
**ä½ç½®**: `EncoderAnySplat.forward()` - Line 653-658

```python
# ä½ç½®: Line 653-658
gaussians = self.gaussian_adapter.forward(
    neural_pts,        # [B, N, 3] - ä½“ç´ åŒ–çš„3Dä½ç½®
    depths,           # [B, N, 1] - æ·±åº¦
    opacity,          # [B, N] - ä¸é€æ˜åº¦
    neural_feats[..., 1:].squeeze(2),  # [B, N, d_in] - Gaussianå‚æ•°ç‰¹å¾
)
```

**GaussianAdapterçš„ä½œç”¨** (è§ `src/model/encoder/common/gaussian_adapter.py`):
1. **å‚æ•°åˆ†è§£** (Line 125): å°† `neural_feats` åˆ†è§£ä¸º `scales`, `rotations`, `sh` (çƒè°ç³»æ•°)
2. **å°ºåº¦æ˜ å°„** (Line 127-128): ä½¿ç”¨softpluså°†å°ºåº¦ç‰¹å¾æ˜ å°„åˆ°åˆç†èŒƒå›´
3. **å››å…ƒæ•°å½’ä¸€åŒ–** (Line 131): å½’ä¸€åŒ–æ—‹è½¬å››å…ƒæ•°
4. **åæ–¹å·®çŸ©é˜µæ„å»º** (Line 136): ä»scaleå’Œrotationæ„å»ºåæ–¹å·®çŸ©é˜µ
5. **è¿”å›Gaussianså¯¹è±¡** (Line 138-146):
   - `means`: 3Dä½ç½® (`neural_pts`)
   - `covariances`: åæ–¹å·®çŸ©é˜µ
   - `harmonics`: çƒè°ç³»æ•°
   - `opacities`: ä¸é€æ˜åº¦
   - `scales`: å°ºåº¦å‚æ•°
   - `rotations`: æ—‹è½¬å››å…ƒæ•°

---

## ğŸ“Š æ•°æ®æµå˜æ¢æ€»ç»“

| æ­¥éª¤ | å˜é‡å | å½¢çŠ¶ | è¯´æ˜ |
|------|--------|------|------|
| è¾“å…¥ | `image` | `[B, V, 3, H, W]` | å¤šè§†è§’å›¾åƒ |
| æ­¥éª¤1 | `aggregated_tokens_list` | `List[Tensor]` | èšåˆç‰¹å¾tokens |
| æ­¥éª¤2 | `pts_all` | `[B, V, H, W, 3]` | åƒç´ çº§3Dç‚¹äº‘ |
| æ­¥éª¤3 | `anchor_feats` | `[B, V, H, W, d_gs]` | åƒç´ çº§Gaussianå‚æ•° |
| **æ­¥éª¤4** | **`voxel_pts`** | **`[num_voxels, 3]`** | **ä½“ç´ åŒ–3Dä½ç½®** |
| **æ­¥éª¤4** | **`voxel_feats`** | **`[num_voxels, d_gs]`** | **ä½“ç´ åŒ–ç‰¹å¾** |
| æ­¥éª¤5 | `neural_pts` | `[B, max_voxels, 3]` | Paddingåçš„ä½“ç´ ä½ç½® |
| æ­¥éª¤5 | `neural_feats` | `[B, max_voxels, d_gs]` | Paddingåçš„ä½“ç´ ç‰¹å¾ |
| æ­¥éª¤6 | `depths`, `opacity` | `[B, max_voxels]` | æ·±åº¦å’Œä¸é€æ˜åº¦ |
| æ­¥éª¤7 | `gaussians` | `Gaussians` | æœ€ç»ˆçš„Gaussianså¯¹è±¡ |

**å…³é”®æ•°é‡å˜åŒ–**:
- **ä½“ç´ åŒ–å‰**: `H Ã— W Ã— V` ä¸ªåƒç´ çº§Gaussians
- **ä½“ç´ åŒ–å**: `num_unique_voxels` ä¸ªä½“ç´ çº§Gaussians (é€šå¸¸ << HÃ—WÃ—V)

---

## ğŸ”§ é…ç½®å‚æ•°

ç›¸å…³é…ç½®åœ¨ `EncoderAnySplatCfg` (Line 194-236):
- `voxelize: bool = False` (Line 236): æ˜¯å¦å¯ç”¨ä½“ç´ åŒ–
- `voxel_size: float`: ä½“ç´ å¤§å° (Line 197, 323)
- `opacity_threshold: float = 0.001`: Opacityå‰ªæé˜ˆå€¼ (Line 217)
- `gs_keep_ratio: float = 1.0`: Gaussianä¿ç•™æ¯”ä¾‹ (Line 218)

---

## ğŸ’¡ å…³é”®ä»£ç æ–‡ä»¶ç´¢å¼•

1. **ä¸»æµç¨‹**: `src/model/encoder/anysplat.py`
   - `EncoderAnySplat.forward()`: Line 448-702
   - `voxelizaton_with_fusion()`: Line 409-446

2. **Gaussiané€‚é…å™¨**: `src/model/encoder/common/gaussian_adapter.py`
   - `UnifiedGaussianAdapter.forward()`: Line 114-146

3. **Gaussianç±»å‹å®šä¹‰**: `src/model/types.py`
   - `Gaussians` dataclass: Line 7-15

---

## ğŸ“ æ€»ç»“

**Voxelized 3D Gaussians ç”Ÿæˆçš„æ ¸å¿ƒæµç¨‹**:
1. âœ… ä»åƒç´ çº§é¢„æµ‹ (HÃ—WÃ—Vä¸ªGaussians)
2. âœ… **ä½“ç´ åŒ–èåˆ** (`voxelizaton_with_fusion`) - **å…³é”®æ­¥éª¤**
3. âœ… å‡å°‘åˆ°ä½“ç´ çº§ (num_voxelsä¸ªGaussians)
4. âœ… è½¬æ¢ä¸ºGaussianså¯¹è±¡

**ä½“ç´ åŒ–çš„ä¼˜åŠ¿**:
- ğŸ¯ å¤§å¹…å‡å°‘Gaussianæ•°é‡ï¼Œæé«˜æ¸²æŸ“æ•ˆç‡
- ğŸ¯ é€šè¿‡åŠ æƒèåˆæé«˜ç©ºé—´ä¸€è‡´æ€§å’Œç‰¹å¾è´¨é‡
- ğŸ¯ è‡ªç„¶å¤„ç†å¤šè§†è§’è§‚æµ‹çš„èåˆ

